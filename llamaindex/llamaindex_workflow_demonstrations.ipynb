{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LlamaIndex Context Snapshot Extraction\n",
        "\n",
        "This notebook demonstrates how to extract a context snapshot from a single LlamaIndex workflow run.\n",
        "\n",
        "## Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… All imports successful!\n",
            "ðŸ“… Current time: 2025-09-12 09:15:35\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "from llama_index.core.workflow import Workflow, StartEvent, StopEvent, step, Event\n",
        "from llama_index.core.workflow.checkpointer import WorkflowCheckpointer\n",
        "from llama_index.core.workflow.context import Context\n",
        "\n",
        "print(\"âœ… All imports successful!\")\n",
        "print(f\"ðŸ“… Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simple Chat Workflow with Context Snapshot Extraction\n",
        "\n",
        "This section shows how to extract a context snapshot from a single workflow run.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“‹ Event classes defined for simple chat demo\n"
          ]
        }
      ],
      "source": [
        "# Define events for simple chat demo\n",
        "class UserMessageEvent(Event):\n",
        "    user_message: str\n",
        "    session_id: str\n",
        "    message_count: int = 0\n",
        "\n",
        "class BotResponseEvent(Event):\n",
        "    user_message: str\n",
        "    bot_response: str\n",
        "    session_id: str\n",
        "    conversation_history: List[Dict] = []\n",
        "\n",
        "print(\"ðŸ“‹ Event classes defined for simple chat demo\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simple Chat Workflow\n",
        "\n",
        "This section shows a simple chat workflow that stores conversation history in context.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”§ Simple chat workflow created with 2 steps\n"
          ]
        }
      ],
      "source": [
        "# Create simple chat workflow using class-based approach\n",
        "class SimpleChatWorkflow(Workflow):\n",
        "    def __init__(self):\n",
        "        super().__init__(timeout=60, verbose=True)\n",
        "    \n",
        "    @step\n",
        "    async def process_user_message(self, ev: StartEvent, ctx: Context) -> UserMessageEvent:\n",
        "        \"\"\"Step 1: Process user message and load conversation history\"\"\"\n",
        "        print(\"\\nðŸ”„ STEP 1: Processing user message...\")\n",
        "        print(f\"ðŸ“¥ Input data: {ev.input_data}\")\n",
        "        \n",
        "        # Load conversation history from context\n",
        "        conversation_history = await ctx.get(\"conversation_history\", [])\n",
        "        print(f\"ðŸ“š Loaded {len(conversation_history)} previous messages from context\")\n",
        "        \n",
        "        user_message = ev.input_data.get(\"user_message\", \"Hello!\")\n",
        "        session_id = ev.input_data.get(\"session_id\", \"demo_session\")\n",
        "        \n",
        "        result = UserMessageEvent(\n",
        "            user_message=user_message,\n",
        "            session_id=session_id,\n",
        "            message_count=len(conversation_history) + 1\n",
        "        )\n",
        "        \n",
        "        print(f\"âœ… User message processed\")\n",
        "        print(f\"ðŸ“¤ Output: {result}\")\n",
        "        \n",
        "        return result\n",
        "    \n",
        "    @step\n",
        "    async def generate_bot_response(self, ev: UserMessageEvent, ctx: Context) -> StopEvent:\n",
        "        \"\"\"Step 2: Generate bot response and update conversation history\"\"\"\n",
        "        print(\"\\nðŸ”„ STEP 2: Generating bot response...\")\n",
        "        print(f\"ðŸ“¥ Input: {ev.user_message} (message #{ev.message_count})\")\n",
        "        \n",
        "        # Get conversation history from context\n",
        "        conversation_history = await ctx.get(\"conversation_history\", [])\n",
        "        print(f\"ðŸ“š Processing with {len(conversation_history)} previous messages in context\")\n",
        "        \n",
        "        # Generate context-aware response\n",
        "        if ev.message_count == 1:\n",
        "            bot_response = \"Hello! This is our first conversation! How can I help you today?\"\n",
        "        elif ev.message_count == 2:\n",
        "            bot_response = \"Nice to see you again! What would you like to know about?\"\n",
        "        else:\n",
        "            bot_response = f\"Thanks for message #{ev.message_count}! I'm here to help with any questions you have.\"\n",
        "        \n",
        "        # Add new message to conversation history\n",
        "        new_message = {\n",
        "            \"user_message\": ev.user_message,\n",
        "            \"bot_response\": bot_response,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"message_number\": ev.message_count\n",
        "        }\n",
        "        \n",
        "        # Update conversation history in context\n",
        "        updated_history = conversation_history + [new_message]\n",
        "        await ctx.set(\"conversation_history\", updated_history)\n",
        "        \n",
        "        print(f\"ðŸ’¾ Updated context with {len(updated_history)} total messages\")\n",
        "        print(f\"ðŸ¤– Bot response: {bot_response}\")\n",
        "        \n",
        "        result = StopEvent(result={\n",
        "            \"session_id\": ev.session_id,\n",
        "            \"user_message\": ev.user_message,\n",
        "            \"bot_response\": bot_response,\n",
        "            \"conversation_history\": updated_history,\n",
        "            \"message_count\": ev.message_count,\n",
        "            \"completed_at\": datetime.now().isoformat()\n",
        "        })\n",
        "        \n",
        "        print(f\"âœ… Bot response generated\")\n",
        "        print(f\"ðŸ“¤ Output: {result.result}\")\n",
        "        \n",
        "        return result\n",
        "\n",
        "# Create workflow instance\n",
        "chat_workflow = SimpleChatWorkflow()\n",
        "print(\"ðŸ”§ Simple chat workflow created with 2 steps\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "ðŸš€ CONTEXT SNAPSHOT EXTRACTION\n",
            "============================================================\n",
            "\n",
            "ðŸ“‹ Running a single workflow instance...\n",
            "ðŸŽ¯ We will extract the context snapshot after the workflow completes\n",
            "ðŸ”§ Checkpointer created for workflow: SimpleChatWorkflow\n",
            "ðŸ“Š Initial checkpoints: 0\n",
            "\n",
            "â³ Waiting for workflow to complete...\n",
            "Running step process_user_message\n",
            "\n",
            "ðŸ”„ STEP 1: Processing user message...\n",
            "ðŸ“¥ Input data: {'user_message': 'Hello! Can you help me with Python?', 'session_id': 'demo_session_123'}\n",
            "ðŸ“š Loaded 0 previous messages from context\n",
            "âœ… User message processed\n",
            "ðŸ“¤ Output: user_message='Hello! Can you help me with Python?' session_id='demo_session_123' message_count=1\n",
            "Step process_user_message produced event UserMessageEvent\n",
            "Running step generate_bot_response\n",
            "\n",
            "ðŸ”„ STEP 2: Generating bot response...\n",
            "ðŸ“¥ Input: Hello! Can you help me with Python? (message #1)\n",
            "ðŸ“š Processing with 0 previous messages in context\n",
            "ðŸ’¾ Updated context with 1 total messages\n",
            "ðŸ¤– Bot response: Hello! This is our first conversation! How can I help you today?\n",
            "âœ… Bot response generated\n",
            "ðŸ“¤ Output: {'session_id': 'demo_session_123', 'user_message': 'Hello! Can you help me with Python?', 'bot_response': 'Hello! This is our first conversation! How can I help you today?', 'conversation_history': [{'user_message': 'Hello! Can you help me with Python?', 'bot_response': 'Hello! This is our first conversation! How can I help you today?', 'timestamp': '2025-09-12T09:15:35.968319', 'message_number': 1}], 'message_count': 1, 'completed_at': '2025-09-12T09:15:35.968319'}\n",
            "Step generate_bot_response produced event StopEvent\n",
            "\n",
            "ðŸŽ‰ Workflow completed!\n",
            "ðŸ“Š Workflow result: {'session_id': 'demo_session_123', 'user_message': 'Hello! Can you help me with Python?', 'bot_response': 'Hello! This is our first conversation! How can I help you today?', 'conversation_history': [{'user_message': 'Hello! Can you help me with Python?', 'bot_response': 'Hello! This is our first conversation! How can I help you today?', 'timestamp': '2025-09-12T09:15:35.968319', 'message_number': 1}], 'message_count': 1, 'completed_at': '2025-09-12T09:15:35.968319'}\n",
            "\n",
            "ðŸ“Š Checking checkpoints...\n",
            "ðŸ“‹ Total checkpoints: 1\n",
            "  Session: 4f1cf0cc-a470-4e1f-9bfb-9eeeebcb3dbc\n",
            "  Number of checkpoints: 2\n",
            "    Checkpoint 1: process_user_message\n",
            "    Checkpoint 2: generate_bot_response\n",
            "\n",
            "ðŸ’¾ Extracting context snapshot...\n",
            "âœ… Context snapshot extracted with 9 keys\n",
            "ðŸ”‘ Top-level keys: ['state', 'streaming_queue', 'queues', 'stepwise', 'event_buffers', 'in_progress', 'accepted_events', 'broker_log', 'is_running']\n",
            "\n",
            "ðŸ“š Conversation history from context (1 messages):\n",
            "  1. User: Hello! Can you help me with Python?\n",
            "     Bot: Hello! This is our first conversation! How can I help you today?\n",
            "     Time: 2025-09-12T09:15:35.968319\n",
            "\n",
            "\n",
            "ðŸ” Context Snapshot Structure:\n",
            "  State type: DictState\n",
            "  Queues: ['_done', 'generate_bot_response', 'process_user_message']\n",
            "  Accepted events: [('process_user_message', 'StartEvent'), ('generate_bot_response', 'UserMessageEvent')]\n",
            "  Broker log entries: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\vince.szabo_hiflylab\\AppData\\Local\\Temp\\ipykernel_23468\\4148767160.py:9: DeprecationWarning: WorkflowCheckpointer is deprecated and will be removed in a future version.\n",
            "  checkpointer = WorkflowCheckpointer(workflow=chat_workflow)\n",
            "C:\\Users\\vince.szabo_hiflylab\\AppData\\Local\\Temp\\ipykernel_23468\\2996156014.py:13: DeprecationWarning: Context.get() is deprecated. Use 'await ctx.store.get()' instead.\n",
            "  conversation_history = await ctx.get(\"conversation_history\", [])\n",
            "C:\\Users\\vince.szabo_hiflylab\\AppData\\Local\\Temp\\ipykernel_23468\\2996156014.py:37: DeprecationWarning: Context.get() is deprecated. Use 'await ctx.store.get()' instead.\n",
            "  conversation_history = await ctx.get(\"conversation_history\", [])\n",
            "C:\\Users\\vince.szabo_hiflylab\\AppData\\Local\\Temp\\ipykernel_23468\\2996156014.py:58: DeprecationWarning: Context.set(key, value) is deprecated. Use 'await ctx.store.set(key, value)' instead.\n",
            "  await ctx.set(\"conversation_history\", updated_history)\n"
          ]
        }
      ],
      "source": [
        "# Demonstrate context snapshot extraction from a single workflow run\n",
        "async def extract_context_snapshot():\n",
        "    global checkpointer  # Make checkpointer global so it can be accessed in other cells\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ðŸš€ CONTEXT SNAPSHOT EXTRACTION\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Create checkpointer\n",
        "    checkpointer = WorkflowCheckpointer(workflow=chat_workflow)\n",
        "    \n",
        "    print(\"\\nðŸ“‹ Running a single workflow instance...\")\n",
        "    print(\"ðŸŽ¯ We will extract the context snapshot after the workflow completes\")\n",
        "    print(f\"ðŸ”§ Checkpointer created for workflow: {type(chat_workflow).__name__}\")\n",
        "    print(f\"ðŸ“Š Initial checkpoints: {len(checkpointer.checkpoints)}\")\n",
        "    \n",
        "    # Run workflow with a single message\n",
        "    handler = checkpointer.run(input_data={\n",
        "        \"user_message\": \"Hello! Can you help me with Python?\",\n",
        "        \"session_id\": \"demo_session_123\"\n",
        "    })\n",
        "    \n",
        "    print(\"\\nâ³ Waiting for workflow to complete...\")\n",
        "    result = await handler\n",
        "    \n",
        "    print(\"\\nðŸŽ‰ Workflow completed!\")\n",
        "    print(f\"ðŸ“Š Workflow result: {result}\")\n",
        "    \n",
        "    # Check if checkpoints were created\n",
        "    print(\"\\nðŸ“Š Checking checkpoints...\")\n",
        "    print(f\"ðŸ“‹ Total checkpoints: {len(checkpointer.checkpoints)}\")\n",
        "    for session_id, checkpoints in checkpointer.checkpoints.items():\n",
        "        print(f\"  Session: {session_id}\")\n",
        "        print(f\"  Number of checkpoints: {len(checkpoints)}\")\n",
        "        for i, checkpoint in enumerate(checkpoints):\n",
        "            print(f\"    Checkpoint {i+1}: {checkpoint.last_completed_step}\")\n",
        "    \n",
        "    # Extract context snapshot\n",
        "    print(\"\\nðŸ’¾ Extracting context snapshot...\")\n",
        "    context_snapshot = handler.ctx.to_dict()\n",
        "    \n",
        "    print(f\"âœ… Context snapshot extracted with {len(context_snapshot)} keys\")\n",
        "    print(f\"ðŸ”‘ Top-level keys: {list(context_snapshot.keys())}\")\n",
        "    \n",
        "    # Show conversation history from context\n",
        "    conversation_history = []\n",
        "    if \"state\" in context_snapshot and \"state_data\" in context_snapshot[\"state\"]:\n",
        "        state_data = context_snapshot[\"state\"][\"state_data\"]\n",
        "        if \"_data\" in state_data and \"conversation_history\" in state_data[\"_data\"]:\n",
        "            # The conversation_history might be stored as a JSON string, so we need to parse it\n",
        "            raw_history = state_data[\"_data\"][\"conversation_history\"]\n",
        "            if isinstance(raw_history, str):\n",
        "                try:\n",
        "                    conversation_history = json.loads(raw_history)\n",
        "                except json.JSONDecodeError:\n",
        "                    conversation_history = []\n",
        "            else:\n",
        "                conversation_history = raw_history\n",
        "    \n",
        "    print(f\"\\nðŸ“š Conversation history from context ({len(conversation_history)} messages):\")\n",
        "    if conversation_history:\n",
        "        for i, msg in enumerate(conversation_history, 1):\n",
        "            print(f\"  {i}. User: {msg['user_message']}\")\n",
        "            print(f\"     Bot: {msg['bot_response']}\")\n",
        "            print(f\"     Time: {msg['timestamp']}\")\n",
        "            print()\n",
        "    else:\n",
        "        print(\"  No conversation history found in context\")\n",
        "    \n",
        "    # Show context structure\n",
        "    print(\"\\nðŸ” Context Snapshot Structure:\")\n",
        "    print(f\"  State type: {context_snapshot.get('state', {}).get('state_type', 'Unknown')}\")\n",
        "    print(f\"  Queues: {list(context_snapshot.get('queues', {}).keys())}\")\n",
        "    print(f\"  Accepted events: {context_snapshot.get('accepted_events', [])}\")\n",
        "    print(f\"  Broker log entries: {len(context_snapshot.get('broker_log', []))}\")\n",
        "    \n",
        "    return context_snapshot\n",
        "\n",
        "# Run the demonstration\n",
        "context_snapshot = await extract_context_snapshot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "ðŸ”„ RESUMING FROM CHECKPOINT\n",
            "============================================================\n",
            "\n",
            "ðŸ“‹ Resuming workflow from the second checkpoint...\n",
            "ðŸŽ¯ We will resume from the 'generate_bot_response' step\n",
            "ðŸ“Š Found 2 checkpoints for session: 4f1cf0cc-a470-4e1f-9bfb-9eeeebcb3dbc\n",
            "  Checkpoint 1: process_user_message\n",
            "  Checkpoint 2: generate_bot_response\n",
            "\n",
            "ðŸ”„ Resuming from checkpoint: id_='2cd74e64-6501-4e47-b099-b6609f2ed382' last_completed_step='generate_bot_response' input_event=UserMessageEvent(user_message='Hello! Can you help me with Python?', session_id='demo_session_123', message_count=1) output_event=StopEvent() ctx_state={'state': {'state_data': {'_data': {'conversation_history': '[{\"user_message\": \"Hello! Can you help me with Python?\", \"bot_response\": \"Hello! This is our first conversation! How can I help you today?\", \"timestamp\": \"2025-09-12T09:15:35.968319\", \"message_number\": 1}]'}}, 'state_type': 'DictState', 'state_module': 'workflows.context.state_store'}, 'streaming_queue': '[]', 'queues': {'_done': '[]', 'generate_bot_response': '[]', 'process_user_message': '[]'}, 'stepwise': False, 'event_buffers': {}, 'in_progress': {'process_user_message': [], 'generate_bot_response': []}, 'accepted_events': [('process_user_message', 'StartEvent'), ('generate_bot_response', 'UserMessageEvent')], 'broker_log': ['{\"__is_pydantic\": true, \"value\": {\"_data\": {\"input_data\": {\"user_message\": \"Hello! Can you help me with Python?\", \"session_id\": \"demo_session_123\"}}}, \"qualified_name\": \"workflows.events.StartEvent\"}', '{\"__is_pydantic\": true, \"value\": {\"user_message\": \"Hello! Can you help me with Python?\", \"session_id\": \"demo_session_123\", \"message_count\": 1}, \"qualified_name\": \"__main__.UserMessageEvent\"}'], 'is_running': True}\n",
            "\n",
            "â³ Waiting for resumed workflow to complete...\n",
            "\n",
            "ðŸŽ‰ Resumed workflow completed!\n",
            "ðŸ“Š Resumed workflow result: {'session_id': 'demo_session_123', 'user_message': 'Hello! Can you help me with Python?', 'bot_response': 'Hello! This is our first conversation! How can I help you today?', 'conversation_history': [{'user_message': 'Hello! Can you help me with Python?', 'bot_response': 'Hello! This is our first conversation! How can I help you today?', 'timestamp': '2025-09-12T09:15:35.968319', 'message_number': 1}], 'message_count': 1, 'completed_at': '2025-09-12T09:15:35.968319'}\n",
            "\n",
            "ðŸ“Š Final checkpoints after resume: 2\n"
          ]
        }
      ],
      "source": [
        "# Resume workflow from the second checkpoint\n",
        "async def resume_from_checkpoint():\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ðŸ”„ RESUMING FROM CHECKPOINT\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Use the same checkpointer from the previous run\n",
        "    print(\"\\nðŸ“‹ Resuming workflow from the second checkpoint...\")\n",
        "    print(\"ðŸŽ¯ We will resume from the 'generate_bot_response' step\")\n",
        "    \n",
        "    # Get the checkpoints from the previous run\n",
        "    if not checkpointer.checkpoints:\n",
        "        print(\"âŒ No checkpoints found! Run the first cell first.\")\n",
        "        return\n",
        "    \n",
        "    # Get the session ID and checkpoints\n",
        "    session_id = list(checkpointer.checkpoints.keys())[0]\n",
        "    checkpoints = checkpointer.checkpoints[session_id]\n",
        "    \n",
        "    print(f\"ðŸ“Š Found {len(checkpoints)} checkpoints for session: {session_id}\")\n",
        "    \n",
        "    # Show available checkpoints\n",
        "    for i, checkpoint in enumerate(checkpoints):\n",
        "        print(f\"  Checkpoint {i+1}: {checkpoint.last_completed_step}\")\n",
        "    \n",
        "    # Resume from the second checkpoint (index 1)\n",
        "    if len(checkpoints) >= 2:\n",
        "        second_checkpoint = checkpoints[1]  # Second checkpoint\n",
        "        print(f\"\\nðŸ”„ Resuming from checkpoint: {second_checkpoint}\")\n",
        "        \n",
        "        # Resume the workflow from the checkpoint\n",
        "        resumed_handler = checkpointer.run_from(checkpoint=second_checkpoint)\n",
        "        \n",
        "        print(\"\\nâ³ Waiting for resumed workflow to complete...\")\n",
        "        result = await resumed_handler\n",
        "        \n",
        "        print(\"\\nðŸŽ‰ Resumed workflow completed!\")\n",
        "        print(f\"ðŸ“Š Resumed workflow result: {result}\")\n",
        "        \n",
        "        # Show final checkpoints after resume\n",
        "        print(f\"\\nðŸ“Š Final checkpoints after resume: {len(checkpointer.checkpoints[session_id])}\")\n",
        "        \n",
        "    else:\n",
        "        print(\"âŒ Not enough checkpoints to resume from the second one\")\n",
        "\n",
        "# Run the resume demonstration\n",
        "await resume_from_checkpoint()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”§ Number workflow created with 2 steps\n",
            "\n",
            "============================================================\n",
            "ðŸ”§ CHECKPOINT EVENT MODIFICATION DEMO\n",
            "============================================================\n",
            "\n",
            "ðŸ“‹ Running workflow with initial number 5...\n",
            "Running step first_step\n",
            "\n",
            "ðŸ”„ STEP 1: Getting initial number...\n",
            "ðŸ“¥ Initial number: 5\n",
            "âœ… First step completed with number: 5\n",
            "Step first_step produced event NumberEvent\n",
            "Running step second_step\n",
            "\n",
            "ðŸ”„ STEP 2: Adding 10 to the number...\n",
            "ðŸ“¥ Input number: 5\n",
            "âž• Adding 10 to 5\n",
            "ðŸŽ¯ Final result: 15\n",
            "Step second_step produced event StopEvent\n",
            "\n",
            "ðŸŽ‰ First run completed!\n",
            "ðŸ“Š Result: {'original_number': 5, 'added_number': 10, 'final_result': 15, 'step_name': 'second_step'}\n",
            "\n",
            "ðŸ“Š Found 2 checkpoints\n",
            "  Checkpoint 1: first_step\n",
            "  Checkpoint 2: second_step\n",
            "  Checkpoint 1: id_='15e0ff9c-4a28-48af-a76f-7c314a9d8b55' last_completed_step='first_step' input_event=StartEvent() output_event=NumberEvent(number=5, step_name='first_step') ctx_state={'state': {'state_data': {'_data': {}}, 'state_type': 'DictState', 'state_module': 'workflows.context.state_store'}, 'streaming_queue': '[]', 'queues': {'_done': '[]', 'first_step': '[]', 'second_step': '[\"{\\\\\"__is_pydantic\\\\\": true, \\\\\"value\\\\\": {\\\\\"_data\\\\\": {\\\\\"input_data\\\\\": {\\\\\"number\\\\\": 5}}}, \\\\\"qualified_name\\\\\": \\\\\"workflows.events.StartEvent\\\\\"}\"]'}, 'stepwise': False, 'event_buffers': {}, 'in_progress': {'first_step': []}, 'accepted_events': [('first_step', 'StartEvent'), ('second_step', 'NumberEvent')], 'broker_log': ['{\"__is_pydantic\": true, \"value\": {\"_data\": {\"input_data\": {\"number\": 5}}}, \"qualified_name\": \"workflows.events.StartEvent\"}'], 'is_running': True}\n",
            "\n",
            "ðŸ” Original checkpoint data:\n",
            "  Checkpoint 1 - Last completed step: first_step\n",
            "  Checkpoint 1 - Output event: number=5 step_name='first_step'\n",
            "  Checkpoint 2 - Last completed step: second_step\n",
            "  Checkpoint 2 - Input event: number=5 step_name='first_step'\n",
            "\n",
            "âœï¸ MODIFYING CHECKPOINT EVENT DATA...\n",
            "  Original number in first checkpoint output: 5\n",
            "  Modified number in first checkpoint output: 20\n",
            "\n",
            "ðŸ”„ Resuming from first checkpoint...\n",
            "  Resuming from step: first_step\n",
            "  Using modified number: 20\n",
            "  This will re-run the second step with the modified number!\n",
            "Running step second_step\n",
            "\n",
            "ðŸ”„ STEP 2: Adding 10 to the number...\n",
            "ðŸ“¥ Input number: 20\n",
            "âž• Adding 10 to 20\n",
            "ðŸŽ¯ Final result: 30\n",
            "Step second_step produced event StopEvent\n",
            "\n",
            "ðŸŽ‰ Resumed workflow completed!\n",
            "ðŸ“Š Modified result: {'original_number': 20, 'added_number': 10, 'final_result': 30, 'step_name': 'second_step'}\n",
            "\n",
            "ðŸ“Š COMPARISON:\n",
            "  Original run result: {'original_number': 5, 'added_number': 10, 'final_result': 15, 'step_name': 'second_step'}\n",
            "  Modified run result: {'original_number': 20, 'added_number': 10, 'final_result': 30, 'step_name': 'second_step'}\n",
            "  âœ… The result changed because we modified the input event data!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\vince.szabo_hiflylab\\AppData\\Local\\Temp\\ipykernel_23468\\733539094.py:60: DeprecationWarning: WorkflowCheckpointer is deprecated and will be removed in a future version.\n",
            "  checkpointer = WorkflowCheckpointer(workflow=number_workflow)\n"
          ]
        }
      ],
      "source": [
        "# Demonstrate modifying checkpoint event data\n",
        "class NumberEvent(Event):\n",
        "    number: int\n",
        "    step_name: str\n",
        "\n",
        "class ResultEvent(Event):\n",
        "    original_number: int\n",
        "    added_number: int\n",
        "    final_result: int\n",
        "    step_name: str\n",
        "\n",
        "class NumberWorkflow(Workflow):\n",
        "    def __init__(self):\n",
        "        super().__init__(timeout=60, verbose=True)\n",
        "    \n",
        "    @step\n",
        "    async def first_step(self, ev: StartEvent, ctx: Context) -> NumberEvent:\n",
        "        \"\"\"Step 1: Get initial number from input\"\"\"\n",
        "        print(\"\\nðŸ”„ STEP 1: Getting initial number...\")\n",
        "        initial_number = ev.input_data.get(\"number\", 5)\n",
        "        print(f\"ðŸ“¥ Initial number: {initial_number}\")\n",
        "        \n",
        "        result = NumberEvent(\n",
        "            number=initial_number,\n",
        "            step_name=\"first_step\"\n",
        "        )\n",
        "        print(f\"âœ… First step completed with number: {result.number}\")\n",
        "        return result\n",
        "    \n",
        "    @step\n",
        "    async def second_step(self, ev: NumberEvent, ctx: Context) -> StopEvent:\n",
        "        \"\"\"Step 2: Add 10 to the number\"\"\"\n",
        "        print(\"\\nðŸ”„ STEP 2: Adding 10 to the number...\")\n",
        "        print(f\"ðŸ“¥ Input number: {ev.number}\")\n",
        "        \n",
        "        added_number = 10\n",
        "        final_result = ev.number + added_number\n",
        "        \n",
        "        print(f\"âž• Adding {added_number} to {ev.number}\")\n",
        "        print(f\"ðŸŽ¯ Final result: {final_result}\")\n",
        "        \n",
        "        return StopEvent(result={\n",
        "            \"original_number\": ev.number,\n",
        "            \"added_number\": added_number,\n",
        "            \"final_result\": final_result,\n",
        "            \"step_name\": \"second_step\"\n",
        "        })\n",
        "\n",
        "# Create the number workflow\n",
        "number_workflow = NumberWorkflow()\n",
        "print(\"ðŸ”§ Number workflow created with 2 steps\")\n",
        "\n",
        "# Demonstrate checkpoint modification\n",
        "async def demonstrate_checkpoint_modification():\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ðŸ”§ CHECKPOINT EVENT MODIFICATION DEMO\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Create checkpointer\n",
        "    checkpointer = WorkflowCheckpointer(workflow=number_workflow)\n",
        "    \n",
        "    print(\"\\nðŸ“‹ Running workflow with initial number 5...\")\n",
        "    handler = checkpointer.run(input_data={\"number\": 5})\n",
        "    result = await handler\n",
        "    \n",
        "    print(f\"\\nðŸŽ‰ First run completed!\")\n",
        "    print(f\"ðŸ“Š Result: {result}\")\n",
        "    \n",
        "    # Get checkpoints\n",
        "    session_id = list(checkpointer.checkpoints.keys())[0]\n",
        "    checkpoints = checkpointer.checkpoints[session_id]\n",
        "    \n",
        "    print(f\"\\nðŸ“Š Found {len(checkpoints)} checkpoints\")\n",
        "    for i, checkpoint in enumerate(checkpoints):\n",
        "        print(f\"  Checkpoint {i+1}: {checkpoint.last_completed_step}\")\n",
        "    \n",
        "    # Show original checkpoint data\n",
        "    if len(checkpoints) >= 2:\n",
        "        first_checkpoint = checkpoints[0]  # First checkpoint (first_step)\n",
        "        second_checkpoint = checkpoints[1]  # Second checkpoint (second_step)\n",
        "        print(f\"  Checkpoint 1: {first_checkpoint}\")\n",
        "        print(f\"\\nðŸ” Original checkpoint data:\")\n",
        "        print(f\"  Checkpoint 1 - Last completed step: {first_checkpoint.last_completed_step}\")\n",
        "        print(f\"  Checkpoint 1 - Output event: {first_checkpoint.output_event}\")\n",
        "        print(f\"  Checkpoint 2 - Last completed step: {second_checkpoint.last_completed_step}\")\n",
        "        print(f\"  Checkpoint 2 - Input event: {second_checkpoint.input_event}\")\n",
        "        \n",
        "        # MODIFY THE CORRECT CHECKPOINT EVENT DATA\n",
        "        print(f\"\\nâœï¸ MODIFYING CHECKPOINT EVENT DATA...\")\n",
        "        print(f\"  Original number in first checkpoint output: {first_checkpoint.output_event.number}\")\n",
        "        \n",
        "        # Change the number from 5 to 20 in the FIRST checkpoint's output event\n",
        "        # This is the NumberEvent that gets passed to the second step\n",
        "        first_checkpoint.output_event.number = 20\n",
        "        print(f\"  Modified number in first checkpoint output: {first_checkpoint.output_event.number}\")\n",
        "        \n",
        "        # Resume from the FIRST checkpoint (so it re-runs the second step with modified data)\n",
        "        print(f\"\\nðŸ”„ Resuming from first checkpoint...\")\n",
        "        print(f\"  Resuming from step: {first_checkpoint.last_completed_step}\")\n",
        "        print(f\"  Using modified number: {first_checkpoint.output_event.number}\")\n",
        "        print(f\"  This will re-run the second step with the modified number!\")\n",
        "        \n",
        "        resumed_handler = checkpointer.run_from(checkpoint=first_checkpoint)\n",
        "        modified_result = await resumed_handler\n",
        "        \n",
        "        print(f\"\\nðŸŽ‰ Resumed workflow completed!\")\n",
        "        print(f\"ðŸ“Š Modified result: {modified_result}\")\n",
        "        \n",
        "        # Compare results\n",
        "        print(f\"\\nðŸ“Š COMPARISON:\")\n",
        "        print(f\"  Original run result: {result}\")\n",
        "        print(f\"  Modified run result: {modified_result}\")\n",
        "        print(f\"  âœ… The result changed because we modified the input event data!\")\n",
        "        \n",
        "    else:\n",
        "        print(\"âŒ Not enough checkpoints to demonstrate modification\")\n",
        "\n",
        "# Run the demonstration\n",
        "await demonstrate_checkpoint_modification()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Human-in-the-Loop Integration\n",
        "\n",
        "This section demonstrates InputRequiredEvent for stopping workflows and waiting for human input.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# InputRequiredEvent - stopping workflow for human input\n",
        "from llama_index.core.workflow import InputRequiredEvent\n",
        "\n",
        "class DocumentReviewEvent(Event):\n",
        "    document: str\n",
        "    status: str = \"pending\"\n",
        "\n",
        "class HumanReviewWorkflow(Workflow):\n",
        "    @step\n",
        "    async def human_review_step(self, ev: StartEvent, ctx: Context) -> InputRequiredEvent:\n",
        "        document = ev.input_data.get(\"document\", \"Sample document content\")\n",
        "        \n",
        "        return InputRequiredEvent(\n",
        "            input_type=\"human_review\",\n",
        "            message=\"Please review this document and approve/reject\",\n",
        "            data={\"document\": document}\n",
        "        )\n",
        "\n",
        "print(\"ðŸ”§ Human-in-the-Loop workflow created - can pause for human input\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Graph Visualization\n",
        "\n",
        "This section demonstrates workflow graph visualization capabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Workflow graph visualization\n",
        "from llama_index.core.workflow import visualize_workflow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class VisualizationWorkflow(Workflow):\n",
        "    @step\n",
        "    async def step_a(self, ev: StartEvent, ctx: Context) -> StopEvent:\n",
        "        return StopEvent(result=\"Step A completed\")\n",
        "    \n",
        "    @step  \n",
        "    async def step_b(self, ev: StartEvent, ctx: Context) -> StopEvent:\n",
        "        return StopEvent(result=\"Step B completed\")\n",
        "\n",
        "# Create workflow and visualize\n",
        "workflow = VisualizationWorkflow()\n",
        "print(\"ðŸ”§ Workflow created for visualization\")\n",
        "\n",
        "# Note: visualize_workflow() creates a graph representation\n",
        "# graph = visualize_workflow(workflow)\n",
        "# graph.render(\"workflow_diagram\", format=\"png\")\n",
        "print(\"ðŸ“Š Graph visualization capability available - efficient workflow visualization\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Observability & Streaming\n",
        "\n",
        "This section demonstrates real-time progress updates and built-in instrumentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Real-time progress updates and instrumentation\n",
        "class StreamingWorkflow(Workflow):\n",
        "    @step\n",
        "    async def streaming_step(self, ev: StartEvent, ctx: Context) -> StopEvent:\n",
        "        # Built-in instrumentation - progress tracking\n",
        "        await ctx.set(\"progress\", 0.25)\n",
        "        print(\"ðŸ“Š Progress: 25% - Starting data processing...\")\n",
        "        \n",
        "        # Simulate processing time\n",
        "        import asyncio\n",
        "        await asyncio.sleep(0.1)\n",
        "        \n",
        "        await ctx.set(\"progress\", 0.50)\n",
        "        print(\"ðŸ“Š Progress: 50% - Processing intermediate data...\")\n",
        "        \n",
        "        await asyncio.sleep(0.1)\n",
        "        \n",
        "        await ctx.set(\"progress\", 0.75)\n",
        "        print(\"ðŸ“Š Progress: 75% - Finalizing results...\")\n",
        "        \n",
        "        await asyncio.sleep(0.1)\n",
        "        \n",
        "        await ctx.set(\"progress\", 1.0)\n",
        "        print(\"ðŸ“Š Progress: 100% - Complete!\")\n",
        "        \n",
        "        return StopEvent(result={\n",
        "            \"message\": \"Streaming workflow completed\",\n",
        "            \"final_progress\": await ctx.get(\"progress\", 0)\n",
        "        })\n",
        "\n",
        "print(\"ðŸ”§ Streaming workflow created - real-time progress updates and instrumentation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Error Handling & Fault Tolerance\n",
        "\n",
        "This section demonstrates event-driven error correction and retry mechanisms.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Event-driven error correction and retry mechanisms\n",
        "class ErrorEvent(Event):\n",
        "    error_message: str\n",
        "    retry_count: int = 0\n",
        "    should_retry: bool = True\n",
        "\n",
        "class SuccessEvent(Event):\n",
        "    result: str\n",
        "    attempts: int\n",
        "\n",
        "class ErrorHandlingWorkflow(Workflow):\n",
        "    @step\n",
        "    async def risky_operation_step(self, ev: StartEvent, ctx: Context) -> Event:\n",
        "        retry_count = await ctx.get(\"retry_count\", 0)\n",
        "        max_retries = 3\n",
        "        \n",
        "        try:\n",
        "            # Simulate a risky operation that might fail\n",
        "            import random\n",
        "            if random.random() < 0.7:  # 70% chance of failure\n",
        "                raise Exception(\"Simulated network error\")\n",
        "            \n",
        "            result = f\"Success after {retry_count + 1} attempts\"\n",
        "            return SuccessEvent(result=result, attempts=retry_count + 1)\n",
        "            \n",
        "        except Exception as e:\n",
        "            if retry_count < max_retries:\n",
        "                await ctx.set(\"retry_count\", retry_count + 1)\n",
        "                print(f\"ðŸ”„ Retry {retry_count + 1}/{max_retries}: {str(e)}\")\n",
        "                return ErrorEvent(\n",
        "                    error_message=str(e), \n",
        "                    retry_count=retry_count + 1,\n",
        "                    should_retry=True\n",
        "                )\n",
        "            else:\n",
        "                return ErrorEvent(\n",
        "                    error_message=f\"Max retries exceeded: {str(e)}\", \n",
        "                    retry_count=retry_count + 1,\n",
        "                    should_retry=False\n",
        "                )\n",
        "\n",
        "print(\"ðŸ”§ Error handling workflow created - event-driven error correction and retry\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Workflow Chaining/Nesting\n",
        "\n",
        "This section demonstrates workflow slots and injection patterns for nested workflows.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Workflow slots and injection patterns\n",
        "from llama_index.core.workflow import (\n",
        "    StartEvent,\n",
        "    StopEvent,\n",
        "    Workflow,\n",
        "    step,\n",
        "    Event,\n",
        "    Context,\n",
        ")\n",
        "\n",
        "class ReflectionEvent(Event):\n",
        "    query: str\n",
        "\n",
        "class ReflectionWorkflow(Workflow):\n",
        "    @step\n",
        "    async def reflect(self, ctx: Context, ev: StartEvent) -> StopEvent:\n",
        "        # Custom reflection logic\n",
        "        improved_query = f\"Enhanced: {ev.input_data.get('query', 'default query')}\"\n",
        "        print(f\"Reflecting on query: {ev.input_data.get('query', 'default query')}\")\n",
        "        return StopEvent(result=improved_query)\n",
        "\n",
        "class MainWorkflow(Workflow):\n",
        "    @step\n",
        "    async def start(\n",
        "        self, ctx: Context, ev: StartEvent, reflection_workflow: Workflow\n",
        "    ) -> ReflectionEvent:\n",
        "        print(\"Starting main workflow with reflection\")\n",
        "        # Run the nested workflow\n",
        "        result = await reflection_workflow.run(query=ev.input_data.get('query', 'default'))\n",
        "        return ReflectionEvent(query=result)\n",
        "    \n",
        "    @step\n",
        "    async def process_query(self, ctx: Context, ev: ReflectionEvent) -> StopEvent:\n",
        "        print(f\"Processing improved query: {ev.query}\")\n",
        "        # Main processing logic here\n",
        "        final_result = f\"Processed: {ev.query}\"\n",
        "        return StopEvent(result=final_result)\n",
        "\n",
        "# Usage example\n",
        "async def run_nested_workflow():\n",
        "    main_workflow = MainWorkflow(timeout=30, verbose=True)\n",
        "    # Add the nested workflow\n",
        "    main_workflow.add_workflows(reflection_workflow=ReflectionWorkflow())\n",
        "    \n",
        "    result = await main_workflow.run(query=\"What is machine learning?\")\n",
        "    return result\n",
        "\n",
        "print(\"ðŸ”§ Nested workflow created - workflow slots and injection patterns\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
